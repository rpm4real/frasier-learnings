{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_df = pd.read_csv('script.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_lab = script_df[['cast','dialog']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the filtering\n",
    "min_samples = 1000\n",
    "def filter_characters(df,min_samples):\n",
    "    \"\"\"Only allow classification of characters with at least some minimum number of samples.\"\"\"\n",
    "    df_cnts = df.groupby('cast').count()\n",
    "    main_chars = df_cnts[df_cnts['dialog']>=min_samples].index\n",
    "    return script_lab[script_lab['cast'].isin(main_chars)].copy()\n",
    "\n",
    "def fix_chars(mySeries): \n",
    "    \"\"\"Remove any chars in the dialogue string which are irrelevant\"\"\"\n",
    "    mySeries = mySeries.str.replace((\"\\[.*\\]\"),'')\n",
    "    return mySeries.apply(str)\n",
    "\n",
    "def filter_length(df,min_words,max_words): \n",
    "    \"\"\"Only allow samples between a min and max length. \"\"\"\n",
    "    num_words = df['dialog'].apply(lambda x: len(x.split()))\n",
    "    return df[(num_words>=5) & (num_words<=50)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filt1 = filter_characters(script_lab,min_samples)\n",
    "script_filt1['dialog'] = fix_chars(script_filt1['dialog'])\n",
    "\n",
    "min_len = 3 \n",
    "max_len = 50\n",
    "script_filt2 = filter_length(script_filt1,min_len,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words \n",
    "def get_vector_representation(script_df,tfidf=False): \n",
    "    \"\"\"Change a dataframe of cast lines into a matrix representation of those lines, and a matrix representation of who said them.\"\"\"\n",
    "    \n",
    "    corpus = script_df['dialog']\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    if tfidf==True: \n",
    "        transformer = TfidfTransformer()\n",
    "        X = transformer.fit_transform(X)\n",
    "    \n",
    "    Y = pd.get_dummies(script_df['cast'])\n",
    "    \n",
    "    return X,Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = get_vector_representation(script_filt,tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y,test_size=.2,random_state=1930)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training, num_features = xtrain.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1200, activation='sigmoid',input_shape=(num_features,)))\n",
    "#model.add(Dropout(.2,noise_shape=None, seed=None))\n",
    "#model.add(Dense(units=4200, activation='sigmoid'))\n",
    "#model.add(Dense(units=500, activation='softmax'))\n",
    "#model.dropout(.2)\n",
    "model.add(Dense(units=240, activation='tanh'))\n",
    "model.add(Dense(units=5, activation='relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "39098/39098 [==============================] - 285s 7ms/step - loss: 7.8634 - acc: 0.4306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5c58e4358>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=1,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9775/9775 [==============================] - 8s 791us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.802059611640013, 0.43508951413357044]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtest,ytest,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 5000)              101285000 \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 780)               3900780   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 120)               93720     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 5)                 605       \n",
      "=================================================================\n",
      "Total params: 105,280,105\n",
      "Trainable params: 105,280,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
